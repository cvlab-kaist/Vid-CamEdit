<p align="center">
  <h1 align="center">Video Camera Trajectory Editing with <br> Generative Rendering from Estimated Geometry</h1>
  <p align="center">
    <a href="https://j0seo.github.io/">Junyoung&nbsp;Seo<sup>*</sup></a>
    Â·
    <a href="https://onground-korea.github.io/">Jisang&nbsp;Han<sup>*</sup></a>
    Â·
    <a href="https://crepejung00.github.io/">Jaewoo&nbsp;Jung<sup>*</sup></a>
    Â·
    <a href="https://jinsy515.github.io/my-page/">Siyoon&nbsp;Jin</a>
    Â·
    <a href="https://scholar.google.com/citations?user=0H3dcPoAAAAJ&hl=en">Joungbin&nbsp;Lee</a>
    <br>
    <a href="https://scholar.google.com/citations?user=D3h3NxwAAAAJ&hl=en">Takuya Narihira</a>
    Â·
    <a href="https://ai.sony/people/Kazumi-Fukuda/">Kazumi Fukuda</a>
    Â·
    <a href="https://scholar.google.com/citations?user=XCRO260AAAAJ">Takashi Shibuya<sup></sup></a>
    Â·
    <a href="https://sunovivid.github.io/">Donghoon Ahn<sup></sup></a>
    Â·
    <a href="https://skhu101.github.io">Shoukang Hu<sup></sup></a>
    <br>
    <a href="https://cvlab.kaist.ac.kr/members/faculty">Seungryong Kim<sup>â€ </sup></a>
    Â·
    <a href="https://www.yukimitsufuji.com">Yuki Mitsufuji<sup>â€ </sup></a>
  </p>
  <h3 align="center"> arXiv 2025 </h3>
  <h3 align="center"><a href="https://arxiv.org/pdf/xxx">Paper </a> | <a href="https://cvlab-kaist.github.io/Vid-CamEdit">Project Page </a> </h3>
  <div align="center"></div>
</p>

<p align="center">
  <a href="">
    <img src="" alt="Logo" width="100%">
  </a>
</p>

<p align="center">
<strong>Provided a input video, our model can generate a novel video that follows a desired camera trajectory.</strong>
</p>



**What to expect:**

- ğŸ› ï¸ [] Training and evaluation code & scripts
- ğŸŒ [] Demo code taking arbitrary videos
